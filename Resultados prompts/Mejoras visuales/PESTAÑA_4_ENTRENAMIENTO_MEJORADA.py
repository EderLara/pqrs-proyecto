# PESTAÃ‘A 4 MEJORADA - ENTRENAMIENTO Y EVALUACIÃ“N

"""
PestaÃ±a reorganizada con:
- Layout mejorado
- VisualizaciÃ³n de progreso
- MÃ©tricas destacadas
- Mejor organizaciÃ³n de informaciÃ³n
"""

# === PESTAÃ‘A 4: ENTRENAMIENTO MEJORADA ===
with tabs[3]:
    st.header("ðŸ§  Modelado y EvaluaciÃ³n")
    
    if 'df_clean' not in st.session_state:
        st.warning("âš ï¸ Cargue y limpie los datos primero en la PestaÃ±a 1")
        st.stop()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SECCIÃ“N 1: CONFIGURACIÃ“N DEL MODELO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    st.markdown("### âš™ï¸ ConfiguraciÃ³n del Modelo")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        version_name = st.text_input(
            "ðŸ“ Nombre de la versiÃ³n",
            value=f"v_{datetime.now().strftime('%Y%m%d_%H%M')}",
            help="Nombre Ãºnico para identificar esta versiÃ³n del modelo"
        )
    
    with col2:
        train_btn = st.button("ðŸš€ Entrenar", use_container_width=True, key="train_btn")
    
    with col3:
        st.info(f"ðŸ“Š Datos: {len(st.session_state.df_clean)} registros")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SECCIÃ“N 2: ENTRENAMIENTO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    if train_btn:
        # Placeholder para progreso
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        
        try:
            # Paso 1: Extraer features
            with status_placeholder.container():
                with st.spinner("ðŸ“Š Extrayendo features..."):
                    X, y_ent, y_iss, vectorizer = data_pipeline.get_features(
                        st.session_state.df_clean
                    )
            
            # Paso 2: Entrenar modelos
            with status_placeholder.container():
                with st.spinner("ðŸ§  Entrenando modelos..."):
                    metrics = model_engine.train(X, y_ent, y_iss, vectorizer)
            
            # Paso 3: Guardar
            with status_placeholder.container():
                with st.spinner("ðŸ’¾ Guardando..."):
                    model_engine.save_version(version_name)
            
            # Ã‰xito
            st.success(f"âœ… Modelo **{version_name}** entrenado y guardado exitosamente!")
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # SECCIÃ“N 3: RESUMEN DE RESULTADOS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            st.markdown("---")
            st.markdown("### ðŸ“Š Resultados del Entrenamiento")
            
            # MÃ©tricas principales en cards
            metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
            
            with metric_col1:
                entity_acc = metrics['entity'].get('accuracy', 0)
                st.metric(
                    "Entity Accuracy",
                    f"{entity_acc:.1%}",
                    delta=f"+{(entity_acc-0.85)*100:.1f}%" if entity_acc > 0.85 else None,
                    delta_color="inverse" if entity_acc < 0.85 else "off"
                )
            
            with metric_col2:
                issue_acc = metrics['issue'].get('accuracy', 0)
                st.metric(
                    "Issue Accuracy",
                    f"{issue_acc:.1%}",
                    delta=f"+{(issue_acc-0.80)*100:.1f}%" if issue_acc > 0.80 else None,
                    delta_color="inverse" if issue_acc < 0.80 else "off"
                )
            
            with metric_col3:
                entity_f1 = metrics['entity'].get('weighted avg', {}).get('f1-score', 0)
                st.metric(
                    "Entity F1-Score",
                    f"{entity_f1:.1%}"
                )
            
            with metric_col4:
                issue_f1 = metrics['issue'].get('weighted avg', {}).get('f1-score', 0)
                st.metric(
                    "Issue F1-Score",
                    f"{issue_f1:.1%}"
                )
            
            st.markdown("---")
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # SECCIÃ“N 4: COMPARACIÃ“N DE MODELOS
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            st.markdown("### ðŸ¤– Detalles de Modelos")
            
            tab_entity, tab_issue = st.tabs([
                "ðŸ¢ Entity Classifier (Logistic Regression)",
                "ðŸ“‹ Issue Classifier (Random Forest)"
            ])
            
            # â”€â”€â”€ TAB 1: ENTITY CLASSIFIER â”€â”€â”€
            with tab_entity:
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.subheader("ðŸ“ˆ MÃ©tricas")
                    entity_metrics = metrics['entity']
                    
                    # Accuracy destacado
                    acc = entity_metrics.get('accuracy', 0)
                    st.metric("Accuracy (Global)", f"{acc:.2%}")
                    
                    # Precision, Recall, F1
                    if 'weighted avg' in entity_metrics:
                        weighted = entity_metrics['weighted avg']
                        st.metric("Precision", f"{weighted.get('precision', 0):.2%}")
                        st.metric("Recall", f"{weighted.get('recall', 0):.2%}")
                        st.metric("F1-Score", f"{weighted.get('f1-score', 0):.2%}")
                
                with col2:
                    st.subheader("ðŸ“Š Matriz de ConfusiÃ³n")
                    fig_cm = Visualizer.plot_confusion_matrix(
                        metrics['cm_entity'],
                        metrics['labels_entity'],
                        "Entity Classifier"
                    )
                    st.pyplot(fig_cm, use_container_width=True)
                
                # Expandible: Detalles por clase
                with st.expander("ðŸ“‹ Detalles por clase"):
                    entity_detail = pd.DataFrame(
                        entity_metrics
                    ).drop(columns=['accuracy', 'macro avg', 'weighted avg'], errors='ignore').T
                    
                    st.dataframe(
                        entity_detail.style.format("{:.2%}"),
                        use_container_width=True
                    )
            
            # â”€â”€â”€ TAB 2: ISSUE CLASSIFIER â”€â”€â”€
            with tab_issue:
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.subheader("ðŸ“ˆ MÃ©tricas")
                    issue_metrics = metrics['issue']
                    
                    # Accuracy destacado
                    acc = issue_metrics.get('accuracy', 0)
                    st.metric("Accuracy (Global)", f"{acc:.2%}")
                    
                    # Precision, Recall, F1
                    if 'weighted avg' in issue_metrics:
                        weighted = issue_metrics['weighted avg']
                        st.metric("Precision", f"{weighted.get('precision', 0):.2%}")
                        st.metric("Recall", f"{weighted.get('recall', 0):.2%}")
                        st.metric("F1-Score", f"{weighted.get('f1-score', 0):.2%}")
                
                with col2:
                    st.subheader("ðŸ“Š Matriz de ConfusiÃ³n")
                    fig_cm = Visualizer.plot_confusion_matrix(
                        metrics['cm_issue'],
                        metrics['labels_issue'],
                        "Issue Classifier"
                    )
                    st.pyplot(fig_cm, use_container_width=True)
                
                # Expandible: Detalles por clase
                with st.expander("ðŸ“‹ Detalles por clase"):
                    issue_detail = pd.DataFrame(
                        issue_metrics
                    ).drop(columns=['accuracy', 'macro avg', 'weighted avg'], errors='ignore').T
                    
                    st.dataframe(
                        issue_detail.style.format("{:.2%}"),
                        use_container_width=True
                    )
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # SECCIÃ“N 5: COMPARACIÃ“N VISUAL
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            st.markdown("---")
            st.markdown("### ðŸ“Š ComparaciÃ³n de Modelos")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # GrÃ¡fico de barras: Accuracy por modelo
                import plotly.graph_objects as go
                
                fig = go.Figure(data=[
                    go.Bar(
                        x=['Entity', 'Issue'],
                        y=[
                            metrics['entity'].get('accuracy', 0),
                            metrics['issue'].get('accuracy', 0)
                        ],
                        marker=dict(
                            color=['#06a77d', '#90e0ef']
                        ),
                        text=[
                            f"{metrics['entity'].get('accuracy', 0):.1%}",
                            f"{metrics['issue'].get('accuracy', 0):.1%}"
                        ],
                        textposition='auto'
                    )
                ])
                
                fig.update_layout(
                    title="Accuracy por Modelo",
                    yaxis_title="Accuracy",
                    xaxis_title="Clasificador",
                    height=400,
                    showlegend=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Tabla comparativa
                comparison_data = {
                    'MÃ©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
                    'Entity': [
                        f"{metrics['entity'].get('accuracy', 0):.2%}",
                        f"{metrics['entity'].get('weighted avg', {}).get('precision', 0):.2%}",
                        f"{metrics['entity'].get('weighted avg', {}).get('recall', 0):.2%}",
                        f"{metrics['entity'].get('weighted avg', {}).get('f1-score', 0):.2%}"
                    ],
                    'Issue': [
                        f"{metrics['issue'].get('accuracy', 0):.2%}",
                        f"{metrics['issue'].get('weighted avg', {}).get('precision', 0):.2%}",
                        f"{metrics['issue'].get('weighted avg', {}).get('recall', 0):.2%}",
                        f"{metrics['issue'].get('weighted avg', {}).get('f1-score', 0):.2%}"
                    ]
                }
                
                df_comparison = pd.DataFrame(comparison_data)
                st.dataframe(df_comparison, use_container_width=True, hide_index=True)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # SECCIÃ“N 6: INFORMACIÃ“N Y ACCIONES
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            st.markdown("---")
            st.markdown("### ðŸ’¾ InformaciÃ³n del Modelo")
            
            info_col1, info_col2, info_col3 = st.columns(3)
            
            with info_col1:
                st.info(f"ðŸ“¦ **VersiÃ³n**: `{version_name}`")
            
            with info_col2:
                st.info(f"ðŸ• **Fecha**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            with info_col3:
                st.success(f"âœ… **Status**: Guardado en disco")
            
            # Notas y recomendaciones
            st.markdown("### ðŸ’¡ Recomendaciones")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if metrics['entity'].get('accuracy', 0) < 0.85:
                    st.warning(
                        "âš ï¸ **Entity Accuracy bajo**: Considera recolectar mÃ¡s datos o ajustar features"
                    )
                else:
                    st.success("âœ… Entity Classifier tiene buena precisiÃ³n")
            
            with col2:
                if metrics['issue'].get('accuracy', 0) < 0.80:
                    st.warning(
                        "âš ï¸ **Issue Accuracy bajo**: Revisa balance de clases o aumenta datos"
                    )
                else:
                    st.success("âœ… Issue Classifier tiene buena precisiÃ³n")
            
            # OpciÃ³n para usar en predicciones
            st.markdown("---")
            st.markdown("### ðŸŽ¯ PrÃ³ximos Pasos")
            
            st.info(
                f"""
                âœ… Modelo **{version_name}** entrenado correctamente
                
                **PrÃ³ximo paso**: Ve a la pestaÃ±a **"5ï¸âƒ£ PredicciÃ³n"** para:
                - Usar este modelo en predicciones
                - Analizar sentimientos
                - Ver resultados con confianza
                """
            )
        
        except Exception as e:
            st.error(f"âŒ Error durante entrenamiento: {str(e)}")
            st.error("Revisa los logs para mÃ¡s detalles")
