# PLAN DE IMPLEMENTACI√ìN PASO A PASO
# PQRS Intelligent Classifier - Sistema Completo

**Fecha:** Diciembre 7, 2024  
**Versi√≥n:** 1.0 - Plan de Ejecuci√≥n  
**Complejidad:** Media-Alta  
**Duraci√≥n Estimada:** 4-6 semanas

---

## üìã √çNDICE

1. [Estructura del Proyecto](#estructura)
2. [Modelos Creados](#modelos-creados)
3. [Plan de Implementaci√≥n Detallado](#plan-detallado)
4. [Pr√≥ximos Pasos Inmediatos](#pr√≥ximos-pasos)
5. [Gu√≠a de Ejecuci√≥n](#gu√≠a-de-ejecuci√≥n)

---

## üìÅ Estructura del Proyecto {#estructura}

```
pqrs_classifier/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # Datos originales
‚îÇ   ‚îî‚îÄ‚îÄ processed/                # Datos preprocesados
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb             # An√°lisis Exploratorio
‚îÇ   ‚îî‚îÄ‚îÄ 02_modeling.ipynb        # Modelado (notebook interactivo)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py            # ‚úì Carga de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.py      # ‚úì Preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extractor.py         # Extracci√≥n de features
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vectorizer.py        # Vectorizaci√≥n de texto
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_classifier.py # Clasificador de entidades
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ issue_classifier.py  # Clasificador de tipos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment_analyzer.py # An√°lisis sentimientos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ severity_scorer.py   # C√°lculo severidad
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_manager.py     # Gesti√≥n versiones
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py            # ‚úì Configuraci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging_utils.py     # Logging
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ       ‚îú‚îÄ‚îÄ models.py            # ‚úì Esquemas DB
‚îÇ       ‚îî‚îÄ‚îÄ db_manager.py        # ‚úì Operaciones DB
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py              # ‚úì Fixtures
‚îÇ   ‚îú‚îÄ‚îÄ test_data_modules.py     # ‚úì Tests datos
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py           # Tests modelos
‚îÇ   ‚îî‚îÄ‚îÄ test_database.py         # Tests BD
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Streamlit app principal
‚îÇ   ‚îî‚îÄ‚îÄ pages/
‚îÇ       ‚îú‚îÄ‚îÄ 01_Home.py           # P√°gina inicio
‚îÇ       ‚îú‚îÄ‚îÄ 02_Classification.py # Clasificaci√≥n individual
‚îÇ       ‚îú‚îÄ‚îÄ 03_Batch_Upload.py  # Carga lotes
‚îÇ       ‚îú‚îÄ‚îÄ 04_History.py        # Historial predicciones
‚îÇ       ‚îî‚îÄ‚îÄ 05_Model_Info.py     # Info modelos
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ v1/                      # Versi√≥n 1 modelos
‚îú‚îÄ‚îÄ requirements.txt             # ‚úì Dependencias
‚îî‚îÄ‚îÄ README.md                    # Documentaci√≥n

‚úì = Archivo ya creado
```

---

## ‚úÖ Modelos Creados Hasta Ahora

### Capa 1: Configuraci√≥n y Constantes
- **`src/utils/config.py`** ‚úì
  - Definici√≥n de rutas
  - Clases de entidades y tipos de hechos
  - Pesos de severidad
  - Palabras clave cr√≠ticas

### Capa 2: Datos
- **`src/data/loader.py`** ‚úì
  - `DataLoader`: Carga CSV/XLSX
  - Validaci√≥n de datos
  - Metadatos del dataset

- **`src/data/preprocessor.py`** ‚úì
  - `TextPreprocessor`: Limpieza de texto
  - Normalizaci√≥n y tokenizaci√≥n
  - `DataCleaner`: Preparaci√≥n de DataFrames
  - Extracci√≥n de features b√°sicas

### Capa 3: Base de Datos
- **`src/database/models.py`** ‚úì
  - `User`: Modelo de usuario
  - `Prediction`: Modelo de predicci√≥n
  - `DatabaseSchema`: Esquemas SQLite

- **`src/database/db_manager.py`** ‚úì
  - `DatabaseManager`: Operaciones CRUD
  - Autenticaci√≥n de usuarios
  - Almacenamiento de predicciones
  - Estad√≠sticas y reportes

### Capa 4: Modelado
- **`notebooks/02_modeling.py`** ‚úì
  - `ModelingPipeline`: Pipeline completo
  - M√©todos para:
    - Carga y exploraci√≥n
    - Feature engineering
    - Entrenamiento (Entity + Issue)
    - Evaluaci√≥n
    - Guardado de modelos
    - Predicci√≥n

### Capa 5: Testing
- **`tests/conftest.py`** ‚úì
  - Fixtures para tests
  - Datos de prueba
  - Directorios temporales

- **`tests/test_data_modules.py`** ‚úì
  - Tests para DataLoader
  - Tests para TextPreprocessor
  - Tests para DataCleaner

---

## üõ†Ô∏è Plan de Implementaci√≥n Detallado {#plan-detallado}

### FASE 1: COMPLETAR BACKEND (Semana 1-2)

#### Semana 1: Modelado en Jupyter

**D√≠a 1-2: Preparaci√≥n del Notebook 02_modeling.ipynb**

```python
# Estructura del notebook:

# SECCI√ìN 1: Imports y Setup
import pandas as pd
import numpy as np
from src.data.loader import DataLoader
from src.data.preprocessor import DataCleaner
from src.models.model_manager import ModelManager

# SECCI√ìN 2: Carga de Datos
loader = DataLoader()
df = loader.load_data("data/raw/pqrs_consolidado.csv")
is_valid, errors = loader.validate_data()

# SECCI√ìN 3: Limpieza y Features
cleaner = DataCleaner()
df_clean = cleaner.clean_dataframe(df)
df_features = cleaner.extract_features(df_clean)

# SECCI√ìN 4: EDA y Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns
# Distribuci√≥n de clases, estad√≠sticas, etc.

# SECCI√ìN 5: Modelado
from notebooks.modeling import ModelingPipeline
pipeline = ModelingPipeline()
pipeline.load_data("data/processed/pqrs_clean.csv")
pipeline.prepare_features()

# Entity Classifier
entity_results = pipeline.train_entity_classifier()
print(f"Entity F1: {entity_results['f1']:.3f}")

# Issue Classifier
issue_results = pipeline.train_issue_classifier()
print(f"Issue F1: {issue_results['f1']:.3f}")

# SECCI√ìN 6: Evaluaci√≥n
evaluation = pipeline.evaluate_models()
# Confusion matrices, reports, etc.

# SECCI√ìN 7: Guardado
pipeline.save_models("models/v1")
```

**Tareas espec√≠ficas:**
1. Preparar datos limpios en CSV
2. Ejecutar EDA interactivo
3. Entrenar y evaluar modelos
4. Generar gr√°ficos de m√©tricas
5. Guardar modelos versi√≥n v1

**Entregables:**
- `notebooks/02_modeling.ipynb` completado
- `models/v1/` con modelos entrenados
- `data/processed/pqrs_clean.csv`
- Report de m√©tricas

---

#### Semana 1: Completar M√≥dulos de Modelos

**ARCHIVO: `src/models/entity_classifier.py`**
```python
class EntityClassifier:
    """Clasificador de Entidad Responsable"""
    
    def __init__(self, model_path: str = None):
        """Initialize entity classifier"""
        
    def train(self, X, y):
        """Train classifier"""
        
    def predict(self, X) -> dict:
        """Predict entity and confidence"""
        
    def evaluate(self, X_test, y_test) -> dict:
        """Return metrics"""
```

**ARCHIVO: `src/models/issue_classifier.py`**
```python
class IssueClassifier:
    """Clasificador de Tipo de Hecho"""
    
    def __init__(self, model_path: str = None):
        """Initialize issue classifier"""
        
    def train(self, X, y):
        """Train with SMOTE for imbalance"""
        
    def predict(self, X) -> dict:
        """Predict issue type and confidence"""
```

**ARCHIVO: `src/models/sentiment_analyzer.py`**
```python
class SentimentAnalyzer:
    """An√°lisis de Sentimientos - MVP approach"""
    
    def __init__(self):
        """Initialize with custom dictionary"""
        self.sentiment_dict = {
            "riesgo": -0.9,
            "peligro": -1.0,
            "accidente": -0.95,
            # ... m√°s palabras
        }
        
    def analyze(self, text: str) -> dict:
        """Return sentiment and score"""
```

**ARCHIVO: `src/models/severity_scorer.py`**
```python
class SeverityScorer:
    """C√°lculo de Severidad/Importancia"""
    
    def score(self, 
              sentiment: float,
              keywords_count: int,
              state: str,
              days_pending: int) -> dict:
        """Calculate severity score 0-10"""
        # score = 0.30*sentiment + 0.25*keywords + ...
        # Return: {"score": 7.2, "level": "YELLOW", "reason": "..."}
```

**ARCHIVO: `src/models/model_manager.py`**
```python
class ModelManager:
    """Gesti√≥n de versiones de modelos"""
    
    def __init__(self, models_dir: str = "models"):
        """Initialize model manager"""
        
    def save_model(self, model, name: str, version: str):
        """Save model with version"""
        
    def load_model(self, name: str, version: str):
        """Load specific model version"""
        
    def get_available_versions(self) -> list:
        """Get list of available versions"""
        
    def get_model_metadata(self, version: str) -> dict:
        """Get model metadata (F1, accuracy, etc)"""
```

**Tareas:**
1. Implementar cada clase con docstrings
2. Integrar con modelos entrenados
3. Usar config.py para constantes
4. Aplicar logging en cada m√©todo

---

#### Semana 2: Features y Vectorizaci√≥n

**ARCHIVO: `src/features/extractor.py`**
```python
class FeatureExtractor:
    """Extracci√≥n de caracter√≠sticas del texto"""
    
    def extract_tfidf(self, texts: List[str]):
        """TF-IDF vectorization"""
        
    def extract_word2vec(self, texts: List[str]):
        """Word2Vec embeddings"""
        
    def extract_keywords(self, text: str) -> dict:
        """Extract critical keywords presence"""
        
    def extract_linguistic(self, text: str) -> dict:
        """Linguistic features (length, complexity, etc)"""
```

**ARCHIVO: `src/features/vectorizer.py`**
```python
class TextVectorizer:
    """Texto vectorization pipeline"""
    
    def __init__(self, method: str = "tfidf"):
        """Initialize vectorizer"""
        
    def fit(self, texts: List[str]):
        """Fit vectorizer"""
        
    def transform(self, texts: List[str]):
        """Transform texts to vectors"""
```

---

### FASE 2: TESTING COMPLETO (Semana 2)

**Completar test files:**

- `tests/test_models.py` - Tests para clasificadores
- `tests/test_database.py` - Tests para BD
- `tests/test_sentiment.py` - Tests para sentimientos
- `tests/test_severity.py` - Tests para severidad

**Ejecutar:**
```bash
pytest tests/ -v --cov=src
```

---

### FASE 3: FRONTEND - STREAMLIT (Semana 3-4)

**ARCHIVO: `app/main.py`**
```python
import streamlit as st
from src.database.db_manager import DatabaseManager
from src.models.model_manager import ModelManager

# Configurar p√°gina
st.set_page_config(
    page_title="PQRS Intelligent Classifier",
    page_icon="üîç",
    layout="wide"
)

# Inicializar sesi√≥n
if 'user' not in st.session_state:
    st.session_state.user = None
    st.session_state.db = DatabaseManager("pqrs_classifier.db")
    st.session_state.model_mgr = ModelManager()

# Router de p√°ginas
page = st.sidebar.radio(
    "Navegaci√≥n",
    ["üè† Home", "üîç Clasificar", "üì§ Carga Masiva", "üìä Historial", "‚ÑπÔ∏è Modelos"]
)

if page == "üè† Home":
    from app.pages import home
    home.show()
elif page == "üîç Clasificar":
    from app.pages import classification
    classification.show()
# ...
```

**ARCHIVO: `app/pages/01_Home.py`**
```python
import streamlit as st

def show():
    st.title("üîç PQRS Intelligent Classifier")
    st.write("Sistema de clasificaci√≥n autom√°tica de Peticiones, Quejas y Reclamos")
    
    # Features overview
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Entidades", "5 Clases", "‚úì")
    with col2:
        st.metric("Tipos Hechos", "6 Clases", "‚úì")
    with col3:
        st.metric("Sentimientos", "4 Niveles", "‚úì")
    with col4:
        st.metric("Severidad", "3 Niveles", "‚úì")
    
    st.divider()
    st.header("Caracter√≠sticas")
    
    st.write("""
    ‚úì Clasificaci√≥n autom√°tica de responsables
    ‚úì Identificaci√≥n de tipo de problema
    ‚úì An√°lisis de sentimientos
    ‚úì Scoring de severidad
    ‚úì Historial de predicciones
    ‚úì Reportes descargables
    """)
```

**ARCHIVO: `app/pages/02_Classification.py`**
```python
import streamlit as st
import time
from src.database.db_manager import DatabaseManager
from src.models.model_manager import ModelManager

def show():
    st.title("üîç Clasificar PQRS")
    
    # Check authentication
    if not st.session_state.get('user'):
        st.warning("Por favor, inicia sesi√≥n primero")
        st.stop()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        description = st.text_area(
            "Descripci√≥n del Hecho",
            height=200,
            placeholder="Ingresa la descripci√≥n del PQRS..."
        )
    
    with col2:
        pqrs_number = st.number_input("PQRS No.", min_value=0)
        model_version = st.selectbox(
            "Versi√≥n Modelo",
            ["v1", "v2"]
        )
    
    if st.button("üöÄ Clasificar", use_container_width=True):
        if not description.strip():
            st.error("Por favor, ingresa una descripci√≥n")
            return
        
        with st.spinner("Procesando..."):
            start_time = time.time()
            
            # Make predictions
            model_mgr = st.session_state.model_mgr
            predictions = model_mgr.predict_all(
                description,
                model_version=model_version
            )
            
            processing_time = time.time() - start_time
            
            # Display results
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "Entidad Responsable",
                    predictions['entity'],
                    f"Confianza: {predictions['entity_confidence']:.1%}"
                )
                st.metric(
                    "Tipo de Hecho",
                    predictions['issue'],
                    f"Confianza: {predictions['issue_confidence']:.1%}"
                )
            
            with col2:
                st.metric(
                    "Sentimiento",
                    predictions['sentiment'],
                    f"Score: {predictions['sentiment_score']:.2f}"
                )
                st.metric(
                    "Severidad",
                    predictions['severity_level'],
                    f"Score: {predictions['severity_score']:.1f}/10"
                )
            
            # Save to database
            db = st.session_state.db
            from src.database.models import Prediction
            
            pred = Prediction(
                user_id=st.session_state.user.id,
                pqrs_number=pqrs_number,
                description=description,
                entity_predicted=predictions['entity'],
                entity_confidence=predictions['entity_confidence'],
                issue_type_predicted=predictions['issue'],
                issue_confidence=predictions['issue_confidence'],
                sentiment_predicted=predictions['sentiment'],
                sentiment_score=predictions['sentiment_score'],
                severity_score=predictions['severity_score'],
                severity_level=predictions['severity_level'],
                model_version=model_version,
                processing_time_ms=processing_time * 1000
            )
            
            db.save_prediction(pred)
            st.success("‚úì Predicci√≥n guardada")
```

**ARCHIVO: `app/pages/04_History.py`**
```python
import streamlit as st
import pandas as pd

def show():
    st.title("üìä Historial de Predicciones")
    
    if not st.session_state.get('user'):
        st.warning("Por favor, inicia sesi√≥n primero")
        st.stop()
    
    db = st.session_state.db
    
    # Filters
    col1, col2, col3 = st.columns(3)
    
    with col1:
        order = st.radio("Ordenar por", ["Descendente", "Ascendente"])
    
    with col2:
        severity_filter = st.multiselect(
            "Filtrar por Severidad",
            ["Urgente", "Importante", "Rutinario"]
        )
    
    with col3:
        model_filter = st.selectbox(
            "Versi√≥n Modelo",
            ["Todas", "v1", "v2"]
        )
    
    # Get predictions
    order_by = "DESC" if order == "Descendente" else "ASC"
    predictions = db.get_user_predictions(
        st.session_state.user.id,
        order_by=order_by,
        limit=1000
    )
    
    # Convert to DataFrame
    pred_data = []
    for pred in predictions:
        pred_data.append({
            "ID": pred.id,
            "Fecha": pred.created_at,
            "PQRS": pred.pqrs_number,
            "Entidad": pred.entity_predicted,
            "Tipo": pred.issue_type_predicted,
            "Sentimiento": pred.sentiment_predicted,
            "Severidad": pred.severity_level,
            "Score": f"{pred.severity_score:.1f}",
            "Modelo": pred.model_version,
            "Confianza Entity": f"{pred.entity_confidence:.1%}"
        })
    
    df = pd.DataFrame(pred_data)
    
    # Display table
    st.dataframe(df, use_container_width=True)
    
    # Export button
    csv = df.to_csv(index=False)
    st.download_button(
        "üì• Descargar CSV",
        csv,
        "predictions.csv",
        "text/csv"
    )
    
    # Statistics
    stats = db.get_statistics(st.session_state.user.id)
    
    col1, col2, col3, col4 = st.columns(4)
    
    col1.metric("Total Predicciones", stats['total'])
    col2.metric("Severidad Promedio", f"{stats['avg_severity']:.2f}")
    col3.metric("Urgentes", stats['severity_distribution'].get('Urgente', 0))
    col4.metric("Tiempo Promedio", "250ms")
```

---

### FASE 4: AUTENTICACI√ìN (Semana 4)

**ARCHIVO: `app/auth.py`**
```python
import streamlit as st
from src.database.db_manager import DatabaseManager

def login():
    """Login page"""
    st.title("üîê Iniciar Sesi√≥n")
    
    username = st.text_input("Usuario")
    password = st.text_input("Contrase√±a", type="password")
    
    if st.button("Entrar"):
        db = st.session_state.db
        user = db.authenticate_user(username, password)
        
        if user:
            st.session_state.user = user
            st.success(f"¬°Bienvenido {user.username}!")
            st.rerun()
        else:
            st.error("Credenciales inv√°lidas")


def signup():
    """Registration page"""
    st.title("üìù Crear Cuenta")
    
    username = st.text_input("Usuario")
    email = st.text_input("Correo")
    password = st.text_input("Contrase√±a", type="password")
    confirm_pwd = st.text_input("Confirmar Contrase√±a", type="password")
    
    if st.button("Crear Cuenta"):
        if password != confirm_pwd:
            st.error("Las contrase√±as no coinciden")
            return
        
        db = st.session_state.db
        success = db.create_user(username, email, password)
        
        if success:
            st.success("‚úì Cuenta creada. Por favor, inicia sesi√≥n")
        else:
            st.error("El usuario o email ya existe")
```

---

## üìã Pr√≥ximos Pasos Inmediatos {#pr√≥ximos-pasos}

### PASOS 1-5 (Esta Semana)

1. **Descarga tu dataset real**
   ```bash
   # Coloca el archivo en:
   data/raw/Consolidado-PQRS-25-03-2015.xlsx
   ```

2. **Crea un notebook de preparaci√≥n**
   ```python
   # notebooks/01_eda.ipynb
   from src.data.loader import DataLoader
   from src.data.preprocessor import DataCleaner
   
   loader = DataLoader()
   df = loader.load_data("data/raw/Consolidado-PQRS-25-03-2015.xlsx")
   
   cleaner = DataCleaner()
   df_clean = cleaner.clean_dataframe(df)
   df_features = cleaner.extract_features(df_clean)
   
   df_clean.to_csv("data/processed/pqrs_clean.csv", index=False)
   ```

3. **Entrena modelos con 02_modeling.ipynb**
   ```python
   from notebooks.modeling import ModelingPipeline
   
   pipeline = ModelingPipeline()
   pipeline.load_data("data/processed/pqrs_clean.csv")
   pipeline.prepare_features()
   pipeline.train_entity_classifier()
   pipeline.train_issue_classifier()
   pipeline.save_models("models/v1")
   ```

4. **Ejecuta tests**
   ```bash
   pytest tests/ -v
   ```

5. **Inicia Streamlit**
   ```bash
   streamlit run app/main.py
   ```

---

## üöÄ Gu√≠a de Ejecuci√≥n {#gu√≠a-de-ejecuci√≥n}

### Configuraci√≥n Inicial

```bash
# 1. Clonar o crear proyecto
mkdir pqrs_classifier
cd pqrs_classifier

# 2. Crear virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Crear estructura de directorios
mkdir -p data/raw data/processed
mkdir -p notebooks models/v1
mkdir -p src/{data,features,models,utils,database}
mkdir -p app/pages tests
```

### requirements.txt
```
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.2.2
matplotlib==3.7.1
seaborn==0.12.2
streamlit==1.24.0
sqlite3  # Built-in
pytest==7.3.1
pytest-cov==4.1.0
imbalanced-learn==0.10.1
python-dotenv==1.0.0
```

### Workflow T√≠pico

```bash
# Semana 1: Preparaci√≥n
1. Ejecutar 01_eda.ipynb
2. Ejecutar 02_modeling.ipynb
3. Revisar m√©tricas

# Semana 2: Testing
pytest tests/ -v

# Semana 3: Frontend
streamlit run app/main.py

# Semana 4: Refinamiento
Ajustar modelos
Mejorar UI
Agregar m√°s features
```

---

## üìû Preguntas Comunes

**P: ¬øPor d√≥nde empiezo exactamente?**  
R: Ejecuta `notebooks/01_eda.ipynb` con tu dataset real. Esto prepara los datos para modelado.

**P: ¬øCu√°nto tarde el entrenamiento?**  
R: 2-5 minutos con dataset de 150 registros en laptop est√°ndar.

**P: ¬øQu√© pasa si los modelos no funcionan bien?**  
R: Ajusta par√°metros en `ModelingPipeline.train_*()` o recoge m√°s datos.

**P: ¬øC√≥mo agrego nuevas versiones de modelos?**  
R: Entrena nuevamente y guarda en `models/v2/`, actualiza config.py.

**P: ¬øC√≥mo se integra con sistemas existentes?**  
R: Exponer ModelManager como API FastAPI o similar.

---

**Pr√≥xima Revisi√≥n:** Despu√©s de completar Semana 1  
**Responsable de Decisiones:** Equipo de Datos
