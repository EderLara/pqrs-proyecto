# GUÃA DE INTEGRACIÃ“N COMPLETA

## ğŸ¯ RESUMEN EJECUTIVO

Has recibido:
1. âœ… **CORRECCIÃ“N DEL ERROR** en `prepare_features()`
2. âœ… **7 MÃ“DULOS COMPLETOS** de ML listos para copiar/pegar
3. âœ… **APLICACIÃ“N STREAMLIT COMPLETA** con 5 pÃ¡ginas

**Archivos entregados HOY:**
- `SOLUCION-ERROR-FEATURES.md` - SoluciÃ³n del error + funciÃ³n diagnÃ³stica
- `MODULOS-1-A-4.py` - MÃ³dulos 1-4 (4 clasificadores)
- `MODULOS-5-A-7.py` - MÃ³dulos 5-7 (Manager, Extractor, Ensemble)
- `APP-STREAMLIT-COMPLETA.py` - App Streamlit lista (sin Batch Upload)

---

## ğŸ“‹ INSTRUCCIONES PASO A PASO

### PASO 1: CORREGIR EL ERROR EN notebooks/modeling.py

**UbicaciÃ³n:** LÃ­nea ~165 en `notebooks/modeling.py`

**AcciÃ³n:** Reemplazar el mÃ©todo `prepare_features()` completo

Ver archivo: `SOLUCION-ERROR-FEATURES.md`

```python
# Copiar COMPLETO el mÃ©todo del archivo SOLUCION-ERROR-FEATURES.md
# Reemplazar en tu clase ModelingPipeline

def prepare_features(self, test_size: float = 0.2, random_state: int = 42) -> None:
    """MÃ©todo corregido con manejo de clases minoritarias..."""
    # 50+ lÃ­neas de cÃ³digo robusto
```

**Resultado esperado despuÃ©s:**
- âœ“ Se filtra automÃ¡ticamente clases con <2 ejemplos
- âœ“ Se aplica SMOTE solo en train
- âœ“ InformaciÃ³n detallada de diagnÃ³stico

---

### PASO 2: CREAR LOS 7 MÃ“DULOS DE ML

**Estructura:**
```
src/models/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ entity_classifier.py       # MÃ“DULO 1
â”œâ”€â”€ issue_classifier.py        # MÃ“DULO 2
â”œâ”€â”€ sentiment_analyzer.py      # MÃ“DULO 3
â”œâ”€â”€ severity_scorer.py         # MÃ“DULO 4
â””â”€â”€ model_manager.py           # MÃ“DULO 5

src/features/
â”œâ”€â”€ __init__.py
â””â”€â”€ extractor.py               # MÃ“DULO 6

# MÃ“DULO 7 va en src/models/
src/models/ensemble_predictor.py
```

**Instrucciones:**

1. Copiar cÃ³digo de `MODULOS-1-A-4.py`:
   - Creo `src/models/entity_classifier.py` (lÃ­neas 1-200)
   - Creo `src/models/issue_classifier.py` (lÃ­neas 200-400)
   - Creo `src/models/sentiment_analyzer.py` (lÃ­neas 400-700)
   - Creo `src/models/severity_scorer.py` (lÃ­neas 700-1000)

2. Copiar cÃ³digo de `MODULOS-5-A-7.py`:
   - Creo `src/models/model_manager.py` (MÃ“DULO 5)
   - Creo `src/features/extractor.py` (MÃ“DULO 6)
   - Creo `src/models/ensemble_predictor.py` (MÃ“DULO 7)

**Validar imports:**

```python
# Al inicio de cada archivo, agregar:
import logging
logger = logging.getLogger(__name__)

# En model_manager.py:
from .entity_classifier import EntityClassifier
from .issue_classifier import IssueClassifier
from .sentiment_analyzer import SentimentAnalyzer
from .severity_scorer import SeverityScorer
```

---

### PASO 3: COPIAR APP STREAMLIT

**UbicaciÃ³n:** `app/main.py`

**AcciÃ³n:** Copiar TODO el cÃ³digo de `APP-STREAMLIT-COMPLETA.py`

**Estructura final:**
```
app/
â”œâ”€â”€ __init__.py
â””â”€â”€ main.py              # Archivo principal
```

**Para ejecutar:**
```bash
streamlit run app/main.py
# Abre http://localhost:8501
```

---

## ğŸ”§ FLUJO COMPLETO DE TRABAJO

### FLUJO 1: ENTRENAMIENTO (Notebooks)

```
1. Ejecutar: notebooks/01_eda.ipynb
   â””â”€ Carga datos
   â””â”€ AnÃ¡lisis exploratorio
   â””â”€ Genera pqrs_clean.csv

2. Ejecutar: notebooks/02_modeling.ipynb
   â””â”€ Carga datos limpios
   â””â”€ Llama a pipeline.diagnose_classes()    â† NUEVA FUNCIÃ“N
   â””â”€ Llama a pipeline.prepare_features()     â† AHORA CORREGIDA
   â””â”€ Entrena entity_classifier
   â””â”€ Entrena issue_classifier
   â””â”€ EvalÃºa modelos
   â””â”€ Guarda en models/v1/
```

### FLUJO 2: PREDICCIÃ“N (App Streamlit)

```
Usuario inicia sesiÃ³n
    â†“
ModelManager carga modelos desde models/v1/
    â†“
Usuario ingresa descripciÃ³n PQRS
    â†“
ModelManager.predict() ejecuta:
    1. Vectorizar con TF-IDF
    2. EntityClassifier.predict()
    3. IssueClassifier.predict()
    4. SentimentAnalyzer.analyze()
    5. SeverityScorer.calculate()
    â†“
Guardar predicciÃ³n en SQLite
    â†“
Mostrar resultados en interfaz
```

---

## ğŸ“Š ESTRUCTURA DE CÃ“DIGO VISUAL

```
notebooks/
â”œâ”€â”€ 01_eda.ipynb              â† ExploraciÃ³n
â””â”€â”€ 02_modeling.ipynb         â† Entrenamiento + CORRECCIÃ“N

src/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ loader.py             âœ“ YA EXISTE
â”‚   â””â”€â”€ preprocessor.py       âœ“ YA EXISTE
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ entity_classifier.py       â† NUEVO (MÃ³dulo 1)
â”‚   â”œâ”€â”€ issue_classifier.py        â† NUEVO (MÃ³dulo 2)
â”‚   â”œâ”€â”€ sentiment_analyzer.py      â† NUEVO (MÃ³dulo 3)
â”‚   â”œâ”€â”€ severity_scorer.py         â† NUEVO (MÃ³dulo 4)
â”‚   â”œâ”€â”€ model_manager.py           â† NUEVO (MÃ³dulo 5)
â”‚   â””â”€â”€ ensemble_predictor.py      â† NUEVO (MÃ³dulo 7)
â”œâ”€â”€ features/
â”‚   â””â”€â”€ extractor.py               â† NUEVO (MÃ³dulo 6)
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ models.py             âœ“ YA EXISTE
â”‚   â””â”€â”€ db_manager.py         âœ“ YA EXISTE
â””â”€â”€ utils/
    â”œâ”€â”€ config.py             âœ“ YA EXISTE
    â””â”€â”€ logging_utils.py      (Opcional)

app/
â””â”€â”€ main.py                   â† NUEVO (App Streamlit)

models/
â””â”€â”€ v1/
    â”œâ”€â”€ entity_classifier.pkl
    â”œâ”€â”€ issue_classifier.pkl
    â”œâ”€â”€ sentiment_analyzer.pkl
    â”œâ”€â”€ severity_scorer.pkl
    â”œâ”€â”€ vectorizer.pkl
    â””â”€â”€ metadata.json
```

---

## ğŸ§ª TESTING DE CADA MÃ“DULO

### Test 1: Entity Classifier

```python
from src.models.entity_classifier import EntityClassifier

# Crear y entrenar
clf = EntityClassifier(model_type='logistic')
clf.train(X_train, y_entity_train)

# Evaluar
results = clf.evaluate(X_test, y_entity_test)
print(f"F1-Score: {results['metrics']['f1']:.3f}")

# PredicciÃ³n
predictions = clf.predict(X_test)
```

### Test 2: Issue Classifier

```python
from src.models.issue_classifier import IssueClassifier

# Crear y entrenar (con SMOTE automÃ¡tico)
clf = IssueClassifier(use_smote=True)
clf.train(X_train, y_issue_train)

# Evaluar
results = clf.evaluate(X_test, y_issue_test)
```

### Test 3: Sentiment Analyzer

```python
from src.models.sentiment_analyzer import SentimentAnalyzer

analyzer = SentimentAnalyzer()

# AnÃ¡lisis simple
result = analyzer.analyze("FALTA PRESENCIA DEL INGENIERO")
print(result['level'])  # VERY_NEGATIVE

# Batch
df_results = analyzer.analyze_batch(texts)
```

### Test 4: Severity Scorer

```python
from src.models.severity_scorer import SeverityScorer

scorer = SeverityScorer()

# Calcular
result = scorer.calculate(
    polarity=-0.8,
    critical_keywords=3,
    text_length=150,
    status='open',
    days_elapsed=45
)
print(result['final_score'])  # 8.5
print(result['level'])        # RED
```

### Test 5: Model Manager

```python
from src.models.model_manager import ModelManager

mgr = ModelManager()

# Guardar versiÃ³n despuÃ©s de entrenamiento
mgr.save_version(
    'v1',
    entity_clf, issue_clf, sentiment_analyzer, severity_scorer,
    vectorizer,
    metrics={'entity_f1': 0.88, 'issue_f1': 0.84}
)

# Cargar versiÃ³n
mgr.load_version('v1')

# PredicciÃ³n completa
prediction = mgr.predict("FALTA PRESENCIA DEL INGENIERO")
# Retorna: entity, issue, sentiment, severity, version
```

---

## ğŸš€ CÃ“MO EJECUTAR

### 1ï¸âƒ£ PREPARACIÃ“N

```bash
cd pqrs_classifier

# Activar venv
source venv/bin/activate

# Instalar dependencias adicionales
pip install textblob imblearn
```

### 2ï¸âƒ£ ENTRENAMIENTO (Notebooks)

```bash
# Terminal 1: Jupyter
jupyter notebook

# Ejecutar:
# 1. notebooks/01_eda.ipynb completo
# 2. notebooks/02_modeling.ipynb hasta SECCIÃ“N 9
```

### 3ï¸âƒ£ APLICACIÃ“N (Streamlit)

```bash
# Terminal 2: Streamlit
streamlit run app/main.py

# Abre: http://localhost:8501
```

### 4ï¸âƒ£ TESTING (Pytest)

```bash
# Terminal 3: Tests
pytest tests/ -v --cov=src
```

---

## ğŸ“ CHECKLIST DE IMPLEMENTACIÃ“N

### ANTES DE CORRER NOTEBOOKS
- [ ] CopiÃ© el mÃ©todo `prepare_features()` corregido en modeling.py
- [ ] AgreguÃ© la funciÃ³n `diagnose_classes()` en ModelingPipeline
- [ ] ImportÃ© TfidfVectorizer, train_test_split, SMOTE al inicio

### ANTES DE CREAR MÃ“DULOS
- [ ] CreÃ© carpetas: src/models/, src/features/
- [ ] AgreguÃ© __init__.py en cada carpeta
- [ ] CopiÃ© imports necesarios en cada archivo

### ANTES DE LANZAR STREAMLIT
- [ ] CopiÃ© app/main.py completamente
- [ ] Los 7 mÃ³dulos estÃ¡n listos e importables
- [ ] DatabaseManager estÃ¡ funcional (ya existe)
- [ ] ModelManager puede cargar desde models/v1/

### ANTES DE IR A PRODUCCIÃ“N
- [ ] Todos los mÃ³dulos tienen docstrings
- [ ] Tests pasan con >80% coverage
- [ ] Base de datos creada y funcional
- [ ] Modelos v1 entrenados y guardados

---

## ğŸ› TROUBLESHOOTING

### Error: "ModuleNotFoundError: No module named 'src.models.entity_classifier'"

**SoluciÃ³n:** AsegÃºrate de:
1. Estar en raÃ­z del proyecto
2. Crear archivos en carpetas correctas
3. Agregar `__init__.py` vacÃ­os en cada carpeta

```bash
# Verificar estructura
tree src/
# Debe mostrar:
# src/
# â”œâ”€â”€ models/
# â”‚   â”œâ”€â”€ __init__.py
# â”‚   â”œâ”€â”€ entity_classifier.py
# â”‚   ...
```

### Error: "ValueError: The least populated class..."

**SoluciÃ³n:** Este ERA el error anterior. Ahora estÃ¡ corregido.

- Ejecuta `pipeline.diagnose_classes()` antes de `prepare_features()`
- Verifica que haya clases con <2 ejemplos
- El cÃ³digo corregido las filtra automÃ¡ticamente

### Error: "FileNotFoundError: models/v1/..."

**SoluciÃ³n:** AsegÃºrate de:
1. Haber entrenado modelos en notebook
2. Haber ejecutado `pipeline.save_models("models/v1")`
3. Verificar que exista carpeta: `ls models/v1/`

---

## ğŸ“ REFERENCIAS RÃPIDAS

**Documentos generados HOY:**
```
SOLUCION-ERROR-FEATURES.md  â† CorrecciÃ³n + diagnÃ³stica
MODULOS-1-A-4.py           â† 4 clasificadores principales
MODULOS-5-A-7.py           â† Manager, Extractor, Ensemble
APP-STREAMLIT-COMPLETA.py  â† App Streamlit funcional
PLAN_IMPLEMENTACION.md     â† Plan completo (generado antes)
QUICKSTART.md              â† GuÃ­a rÃ¡pida (generado antes)
```

**Comandos Ãºtiles:**
```bash
# Jupyter
jupyter notebook notebooks/02_modeling.ipynb

# Streamlit
streamlit run app/main.py

# Tests
pytest tests/ -v

# Verificar imports
python -c "from src.models.entity_classifier import EntityClassifier"
```

---

## âœ… INDICADORES DE Ã‰XITO

âœ“ Notebooks ejecutan sin errores  
âœ“ Modelos se guardan en models/v1/  
âœ“ App Streamlit inicia correctamente  
âœ“ Puedo hacer login/signup  
âœ“ Puedo clasificar un PQRS  
âœ“ Predicciones se guardan en BD  
âœ“ Puedo ver historial de predicciones  
âœ“ BotÃ³n de descarga CSV funciona  

---

## ğŸ“ PRÃ“XIMOS PASOS (SEMANA 2)

1. Agregar pÃ¡gina de Batch Upload (carga masiva)
2. Completar pÃ¡gina de Model Info con metadata real
3. Crear tests unitarios para cada mÃ³dulo
4. Optimizar performance de predicciones
5. Agregar grÃ¡ficos en dashboard

---

**Preparado:** Diciembre 7, 2025
**Status:** Listo para integraciÃ³n âœ…
**Tiempo estimado de integraciÃ³n:** 2-3 horas

Â¡Ã‰XITO CON LA IMPLEMENTACIÃ“N! ğŸš€
